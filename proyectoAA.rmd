---
title: "Trabajo 3"
author: "Samuel Cardenete Rodríguez y Juan José Sierra González"
date: "2 de junio de 2017"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
set.seed(5)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/")

library("AppliedPredictiveModeling")

library("caret")
library("leaps")
library("glmnet")
library("readr")

```
\newpage

##Introducción:
Para la realización de esta práctica obtendremos el ajuste de modelos lineales basados en dos problemas centrados en dos conjuntos de datos diferentes. En primer lugar trabajaremos con un problema de clasificación, basado en el conjunto de datos "South African Heart Disease", para el reconocimiento de enfermedades cardiovasculares en una población de Sudáfrica; y en segundo lugar con un problema de regresión, basado en el conjunto de datos "Los Angeles Ozone", para predecir los niveles de ozono en Los Angeles.
\newline

Comenzaremos primeramente abordando el problema de clasificación:

##Clasificación: "South African Heart Disease"
En este caso nos encontramos frente a un problema de clasificación, tal y como hemos visto anteriormente. Se trata de un conjunto de datos que clasifica individuos de una población de Sudáfrica, indicando si padecen o no una enfermedad del corazón en función de los hábitos de vida (consumo de tabaco, obesidad, alcohol...).
\newline
Como primer paso para abordar el problema, leeremos los datos y los dividiremos seleccionando nuestro conjunto de entrenamiento y de prueba.

###Lectura de datos:
Procedemos a la lectura de la base de datos de clasificación 'South African Heart Disease'. \newline

```{r}
datos_housing = as.data.frame( read_csv("datos/housing.data"))
head(datos_housing)
```



###Conjuntos de training y test usados
A continuación, realizaremos el particionamiento del conjunto de datos. Para el conjunto 'train' de entrenamiento emplearemos el 80% del conjunto total de los datos, de forma que el 20% restante será empleado para test. Hemos decidido utilizar este porcentaje dado que se nos ha explicado que un buen reparto entre train y test oscila entre dos terceras partes para train, o bien hasta un 80%, utilizando el resto para test.\newline
Procedemos al particionamiento de los datos, así como a su almacenamiento en respectivas variables:
```{r}
#Si queremos obtener un conjunto de indices train para luego ejecutar un modelo lineal sobre el train:
train = sample (nrow(datos_housing), round(nrow(datos_housing)*0.8))
#definimos ambos conjuntos en dos data.frame diferentes:
housing_train = datos_housing[train,]
housing_test = datos_housing[-train,]
```


###Preprocesamiento de los datos
Antes de entrar en el preprocesamiento, consideramos interesante realizar una vista preliminar de las gráficas de dispersión de cada atributo de la base de datos siendo reflejado con todos los demás. Así obtenemos una matriz simétrica de gráficas, con los colores indicando la etiqueta según padezca enfermedad (rojo) o no (verde):

```{r}
pairs(datos_housing)
```
\newline
Al representar la matriz de diagramas podemos hacernos una primera idea de la dispersión de los datos. Como podemos observar esta dispersión es alta, y a priori los únicos atributos que consideramos que pueden estar sustancialmente relacionados entre sí son 'adiposity' y 'obesity'.

Como estamos tratando un problema de clasificación binaria, generar las gráficas del atributo clase no nos da ninguna ventaja, pero lo hemos dejado en la matriz final para que se pueda apreciar que no aporta ninguna información. Esto es debido a que para todos los atributos, existen casos de ambas clases. De forma contraria, la clase se podría llegar a definir en función de un único parámetro, algo prácticamente inimaginable en un problema real.

Veamos entonces si es posible realizar una reducción de la dimensionalidad de los datos mediante la aplicación de PCA (Computing the Principal Components) sobre el conjunto de datos para intentar comprobar si existen atributos redundantes. Estos atributos redundantes podrían ser recombinados en nuevas características producto de combinaciones lineales de ellos. Prestaremos especial atención a los atributos 'obesity' y 'adiposity' por el motivo indicado anteriormente. \newline

PCA calcula la varianza de cada atributo respecto a los demás, de forma que aquellos atributos que posean menor varianza (cercana a cero) con respecto a los demás serán considerados como redundantes.\newline

Además, para no arriesgar mucho (puesto que PCA trabaja "a ciegas") representaremos sólo aquellos componentes que expliquen hasta el 90% de la variabilidad de los datos (es necesario que los datos estén escalados y centrados para aplicar PCA):

```{r}
housingTrans = preProcess(datos_housing[,-which(names(datos_housing) == "MEDV")], method = c("BoxCox", "center", "scale", "pca"), thresh = 0.9)
housingTrans$rotation
```
Como podemos observar en la tabla, se han reducido los atributos a 8 atributos (combinaciones lineales de los 10 anteriores).
Pero si observamos las varianzas de cada atributo en la tabla respecto al resto de atributos, vemos que no existe ningun atributo cuyas varianzas sean cercanas todas a 0. Aún así, para asegurarnos lo comprobamos mediante la siguiente función:
```{r}
nearZeroVar(housingTrans$rotation)
```
Como comprobamos con la función nearZeroVar no existe ningun atributo cuyas varianzas respecto a las demás sean todas cercanas a 0, y por tanto todos los atributos son considerados representativos, pues poseen dispersión. En conclusión, no realizaremos ninguna reducción de atributos.\newline

Para conlcuir el preprocesamiento de los datos, realizaremos las siguientes operaciones sobre ellos:

* \textbf{Escalado}: Se trata de dividir cada uno de los atributos por su desviación típica.
* \textbf{Centrado}: Calculamos la media de cada atributo y se la restamos para cada valor.
* \textbf{Box-Cox}: Se trata de intentar reducir el sesgo de cada atributo, para intentar hacer este mas próximo a una distribución Gaussiana.

Para aplicar las transformaciones, emplearemos la función preProcess sobre nuestro conjunto train, de forma que realizando un predict sobre el objeto transformación obtenido, obtengamos el conjunto de datos train preprocesado. A continuación, realizaremos las mismas transformaciones sobre el conjunto de test, utilizando el mismo objeto transformación:

```{r}
housingTrans = preProcess(housing_train[,-which(names(housing_train) == "MEDV")],
                            method = c("BoxCox", "center", "scale"),thresh = 0.9)

housing_train[,-which(names(housing_train) == "MEDV")]=predict(housingTrans,
         housing_train[,-which(names(housing_train) == "MEDV")])

housing_test[,-which(names(housing_test) == "MEDV")] =predict(housingTrans,housing_test[,-which(names(housing_test) == "MEDV")])
```


###Estimación de parámetros
Antes de realizar un modelo, veamos cuáles son las características más representativas (las que ofrecen varianza mayor con respecto al resto de datos), de forma que no empecemos a realizar modelos a ciegas, sino fijándonos en la calidad de sus atributos.\newline

Para ello emplearemos la función regsubsets. Esta función realiza una búsqueda exhaustiva (empleando Branch&Bound) de las mejores agrupaciones de atributos en nuestro conjunto de entrenamiento para predecir en una regresión lineal:

```{r}
regsub_housing =regsubsets(datos_housing[,-which(names(datos_housing) == "MEDV")],
                             datos_housing[,which(names(datos_housing) == "MEDV")])

summary(regsub_housing)
```

En la gráfica aportada por la función, obtenemos los atributos más representativos en caso de realizar un modelo con 'n' parámetros (filas), de forma que según el número de atributos que deseamos para nuestro modelo nos estíma cuales serían los parámetros más representativos a emplear. Nuestro criterio a seguir a la hora de generar modelos lineales será, no obstante, tratar de predecir utilizando las agrupaciones de atributos que la función considera representativos, Es decir, si queremos realizar un modelo con n características, utilizaremos aquellas que estén marcadas con una estrella para la fila n. Para mostrar un ejemplo que explique la gráfica, si queremos utilizar 3 atributos para el modelo, escogeremos 'age', 'famhist' y 'tobacco'.

Ahora que sabemos cómo elegir las características más recomendables para realizar modelos, podremos construir una serie de ellos con algunas de estas características y validar con el conjunto de test para comprobar los errores que reflejan.


###Regularización

Procedamos ahora  a realizar un análisis para ver si es interesante aplicar una regularización empleando Weight-decay mediante la función glmnet. Dicha función recibe los siguientes hiperparámetros:

* \textbf{Alpha}: Para aplicar el weight-decay utilizaremos dicho argumento con valor 0.

* \textbf{Lambda}: Parámetro de regularización. (Multiplica la matriz de identidad)

Hace falta tener en cuenta antes la correcta elección del lambda, de forma que escojamos el que mejores resultados nos pueda arrojar. En lugar de seleccionarlo de forma arbitraria, será mejor emplear validación cruzada:

```{r}
etiquetas = housing_train[,which(names(housing_train) == "MEDV")]
tr = housing_train[,-which(names(housing_train) == "MEDV")]
tr = as.matrix(tr)
crossvalidation =cv.glmnet(tr,etiquetas,alpha=0)
print(crossvalidation$lambda.min)
```
Una vez obtenido el lambda que proporciona un menor $E_{out}$, procedemos a generar un modelo de regularización, en primer lugar empleando el valor de lambda generado por validación cruzada, y en segundo lugar empleando un lambda igual a cero, de forma que no apliquemos regularización. El objetivo será comprobar si los parámetros obtenidos son significativamente diferentes como para que merezca la pena realizar regularización en nuestros modelos.

```{r}
modelo_reg = glmnet(tr,etiquetas,alpha=0,lambda=crossvalidation$lambda.min)
print(modelo_reg)
```

Aplicando regularización con el lambda obtenido tras la validación cruzada obtenemos una desviación del 0.237. Probemos ahora no aplizando regularización, empleando un hiperparámetro lambda de 0, y comprobemos su desviación:

```{r}
modelo_reg = glmnet(tr,etiquetas,alpha=0,lambda=0)
print(modelo_reg)
```

Como podemos comprobar, las desviaciones obtenidas empleando o no regularización mediante weight-decay son similares (0.237 frente a 0.241), por tanto, comcluimos en que emplear regularización no merece la pena.

###Definición de modelos

Para empezar, calculamos un sencillo modelo lineal con el que intentamos predecir 'MEDV' (nuestras etiquetas) a partir del atributo más representativo, en nuestro caso y como hemos comprobado, 'age'.\newline

```{r}
m_muestra_housing = lm(MEDV ~ age, data=housing_train)
```

Para el cálculo del error, y a fin de intentar aportar un punto de generalización al problema a abordar, definimos una función que calcula el error (porcentaje de etiquetas mal clasificadas en función de etiquetas totales) y muestra la matriz de confusión en el conjunto de test a partir de un modelo:

```{r errorEtiquetas}
calculoErrorMatrizConfusion  = function (modelo, test, etiquetas, imprimir_matriz=TRUE){
  # Una vez calculado el modelo, empleamos la función predict
  # para obtener la probabilidad de cada etiqueta.
  prob_test = predict(modelo, test[,-which(names(test) == etiquetas)], type="response")

  pred_test = rep(0, length(prob_test))
   # predicciones por defecto 0
  pred_test[prob_test >=0.5] = 1
   # >= 0.5 clase 1
  matriz_conf = table(pred_test, test[,which(names(test) == etiquetas)])
  if (imprimir_matriz)
    print(matriz_conf)

  etest = mean(pred_test != test[,which(names(test) == etiquetas)])
}
```

Utilizamos nuestra función para calcular el error del modelo de muestra generado anteriormente:

```{r}
etest_mmuestrasud = calculoErrorMatrizConfusion(m_muestra_housing, housing_test, "MEDV")
etest_mmuestrasud
```
Obtenemos un error de 0.337, pero se trata de un modelo excesivamente simple como para reflejar buenos resultados en un problema real. Por tanto busquemos un modelo diferente empleando otra carasterística, la siguiente más representativa en el conjunto de datos, que en nuestro caso es 'famhist':

```{r}
m1_housing = lm(MEDV ~ age + famhist, data=housing_train)

etest_m1sud = calculoErrorMatrizConfusion(m1_housing, housing_test, "MEDV")
etest_m1sud
```

Utilizando dos características el error en el conjunto de test desciende hasta un 0.326. Seguimos probando nuevos modelos, así que añadimos la siguiente característica recomendada por regsubsets, 'tobacco':

```{r}
m2_housing = lm(MEDV ~ age + famhist + tobacco, data=housing_train)

etest_m2sud = calculoErrorMatrizConfusion(m2_housing, housing_test, "MEDV")
etest_m2sud
```

Un error reflejado de 0.293 ya se acerca más a lo que buscamos, poco a poco vamos avanzando hacia un error menor en el conjunto de validación. Como aún nos queda una buena cantidad de características por probar, añadimos una más al siguiente modelo, 'ldl':

```{r}
m3_housing = lm(MEDV ~ age + famhist + tobacco + ldl, data=housing_train)

etest_m3sud = calculoErrorMatrizConfusion(m3_housing, housing_test, "MEDV")
etest_m3sud
```

En esta ocasión tenemos un error de 0.261, que mejora sustancialmente al que teníamos antes. Probemos con la siguiente característica, 'typea':

```{r}
m4_housing = lm(MEDV ~ age + famhist + tobacco + ldl + typea, data=housing_train)

etest_m4sud = calculoErrorMatrizConfusion(m4_housing, housing_test, "MEDV")
etest_m4sud
```

El error se reduce a 0.25, lo podemos empezar a considerar un error aceptable. No obstante, sigamos probando a añadir la siguiente característica según regsubsets, 'obesity':

```{r}
m5_housing = lm(MEDV ~ age + famhist + tobacco + ldl + typea + obesity, data=housing_train)

etest_m5sud = calculoErrorMatrizConfusion(m5_housing, housing_test, "MEDV")
etest_m5sud
```

Aquí encontramos el primer bache, y es que aumentando el número de características empeoramos el error en el test. Seguramente sea debido a sobreajuste, pero para asegurarnos vamos a sustituir 'obesity' por el siguiente atributo más válido según regsubsets, 'sbp':

```{r}
m6_housing = lm(MEDV ~ age + famhist + tobacco + ldl + typea + sbp, data=housing_train)

etest_m6sud = calculoErrorMatrizConfusion(m6_housing, housing_test, "MEDV")
etest_m6sud
```

Efectivamente, seguimos encontrando errores peores, por lo que abandonamos esta línea de exploración al estar enfrentándonos a una base de datos no lineal. Para mejorar el error hemos realizado diferentes transformaciones no lineales sobre los atributos seleccionados como más representativos.\newline

Volvemos al modelo en el que menor error obtuvimos, el formado por los 5 mejores atributos según regsubsets, y probamos a utilizar una variable cuadrática, en este caso elevar al cuadrado la característica 'age':

```{r}
m7_housing = lm(MEDV ~ I(age^2) + famhist + tobacco + ldl + typea, data=housing_train)

eout_m7sud = calculoErrorMatrizConfusion(m7_housing, housing_test, "MEDV")
eout_m7sud
```

En este modelo hemos conseguido otra mejora, esta vez el error desciende hasta 0.239. Seguiremos intentando encontrar mejores errores realizando nuevas transformaciones, ahora una cúbica.

```{r}
m8_housing = lm(MEDV ~ I(age^3) + famhist + tobacco + ldl + typea, data=housing_train)

eout_m8sud = calculoErrorMatrizConfusion(m8_housing, housing_test, "MEDV")
eout_m8sud
```

El error no es malo pero sigue siendo un peor modelo que el mejor que hemos generado ahora mismo. Hemos comprobado también que es contraproducente realizar transformaciones con logaritmos y raíces debido a la cantidad de datos negativos que tiene la base de datos una vez normalizada.

En resumen, tras realizar distintas combinaciones de atributos y tratar de predecir con ellos, utilizando alguna transformación no lineal, experimentalmente hemos reducido el error fuera de la muestra a un 0.239. Este error se ha obtenido con un modelo con transformación cuadrática sobre el atributo 'age' (el que mejor representa la muestra como hemos visto en regSubsets) y utilizando los 4 siguientes mejores atributos.

###Estimacion del error $E_{out}$
Una vez que hemos comprobado qué modelo nos aporta un mejor resultado, vamos a proceder a realizar una estimación del $E_{out}$ de forma que obtengamos un valor más representativo que un error puntual en un par de conjuntos train-test.

Para ello vamos a realizar un experimento repitiendo el proceso completo, desde la generación de particiones, tanto train como test, con la misma proporción realizada anteriormente (0.8 para train y 0.2 para test), hasta la definición de los modelos y cálculo del $E_{test}$. Repetiremos el proceso 100 veces y obtendremos la media de los $E_{test}$, considerándolo una buena estimación del $E_{out}$ para el modelo.

Definamos una función que realice tanto la generación y el particionado, así como las transformaciones sobre los conjuntos de datos y que devuelva el error generado por el mejor modelo obtenido:

```{r generaErrorParticionhousing}
generarErrorParticionhousing = function(datos){
  #Si queremos obtener un conjunto de indices train para luego ejecutar un modelo lineal sobre el train:
  indices_train = sample (nrow(datos), round(nrow(datos)*0.7))
  #definimos ambos conjuntos en dos data.frame diferentes:
  housing_train = datos[indices_train,]
  housing_test = datos[-indices_train,]

  #TRANSFORMACIONES:
  housingTrans = preProcess(housing_train[,-which(names(datos_housing) == "MEDV")], method = c("BoxCox", "center", "scale"),thresh = 0.8)
housing_train[,-which(names(housing_train) == "MEDV")] =predict(housingTrans,housing_train[,-which(names(housing_train) == "MEDV")])
housing_test[,-which(names(housing_test) == "MEDV")] =predict(housingTrans,housing_test[,-which(names(housing_test) == "MEDV")])

#EVALUACION DEL MODELO
modelo_housing = lm(MEDV ~ I(age^2) + famhist + tobacco + ldl + typea, data=housing_train)

etest = calculoErrorMatrizConfusion(modelo_housing, housing_test, "MEDV", FALSE)
etest
}

mean(replicate(100, generarErrorParticionhousing(datos_housing)))
```

Como podemos ver, obtenemos una estimación del $E_{out}$ de 0.286. Este error representa mejor el error real obtenido por nuestro modelo de regresión lineal, aunque sea peor que el error puntual que teníamos antes. Seguramente esto se deba a que para los conjuntos train y test definidos anteriormente el modelo se ajustaba particularmente bien, mientras que de forma general en el problema ese modelo no llega a ser tan bueno.


###Conclusión y modelo final seleccionado

Tras los diferentes modelos generados, sin aplicar regularización al considerar que la desviación no varía de forma significativa entre hacerla y no hacerla, y habiendo utilizado distintas combinaciones de atributos, tratando de optimizar con transformaciones no lineales, hemos conlcuido que el mejor modelo que hemos podido encontrar ha sido aquel que utiliza la agrupación de los 5 mejores atributos según regsubsets, y con una transformación cuadrática del atributo 'age'.

Con este modelo hemos reducido la tasa de error hasta un 23.9% con los conjuntos generados inicialmente. Si consideramos la distribución de los datos que observamos en la matriz de gráficas al comienzo del problema, y según hemos comprobado de forma experimental, la base de datos no es lineal, y con un modelo lineal no podremos ajustar de mucha mejor forma los datos. A pesar de ello, decidimos empezar por ahí para encontrar qué características son más representativas a la hora de reducir el error. Hemos construido diferentes modelos combinando los atributos que mayor varianza presentan (más representativos) y hemos ido reduciendo el error hasta que se ha empezado a producir sobreajuste. A partir de aquí, añadir más atributos sólo nos continúa sobreajustando la función, provocando que se produzcan muchas curvas en la función que dificulten generalizar los datos del conjunto de test.

Llegados a este punto, como no nos conviene añadir más atributos y puesto que nos encontramos frente a un modelo no lineal, consideramos realizar algunas transformaciones no lineales sobre los atributos que ya tenemos, y encontramos el mejor error realizando una transformación cuadrática sobre el atributo 'age'. Optamos por esto dado que contamos con unos datos muy dispersos y difícilmente separables con una función lineal. Probando con nuevas transformaciones no logramos mejor resultado así que nos quedamos con este modelo.

A pesar de todo, el error que da en estos conjuntos train-test no nos aporta más que una valoración puntual del modelo, por lo que hemos considerado oportuno realizar 100 versiones del modelo realizando distintas particiones de los datos, a fin de poder obtener un error medio más representativo y que resulte en una buena estimación del $E_{out}$. El error medio obtenido es peor, pero sin embargo resulta mucho más válido al tratarse de un error contrastado en un número considerable de casos, y no en un caso puntual como era el primero que obtuvimos.

Como conclusión final, un modelo que utilice suficiente número de atributos para predecir (sin llegar al límite de sobreajuste) y que contenga algún tipo de transformación no lineal es comprensible que refleje buenos resultados en un problema real con datos dispersos y con ruido. Dentro de los distintos modelos que cumplan esas características, de forma experimental hemos podido comparar varios y nos hemos quedado con el anteriormente mencionado.

##Regresión: "LA Ozone"
En este caso, el problema a abordar se basa en los registros de concentración de ozono en la atmósfera de Los Angeles. Se trata de un problema de regresión donde buscamos predecir la cota máxima por hora de la concentración de ozono de la ciudad de Upland, California.

Los atributos pertenecientes al conjunto de datos son los siguientes:

* \textbf{vh}: Indica la presión atmosférica medida en la base aérea de los Angeles.
* \textbf{wind}: Velocidad el viento en mph.
* \textbf{humidity}: Representa la humedad en el aire.
* \textbf{temp}: La temperatura que hay cuando se realiza la medición.
* \textbf{ibh}: Altura a partir de la cuál la presión atmosférica cambia.
* \textbf{dpg}: Nos indica el gradiante de la presión atmosférica actual.
* \textbf{ibt}: Altura a partir de la cuál la temperatura atmosférica cambia.
* \textbf{vis}: Nivel de visibilidad.
* \textbf{doy}: Día en el que se realizaron las mediciones anteriormente mencionadas.


Procedamos a realizar la lectura de los datos obtenidos:

```{r}
datos_ozone = read.csv("./datos/LAozone.data")
head(datos_ozone)
```

Si analizamos los datos obtenidos, podemos observar que existe un atributo, 'doy', que actúa como clave primaria, es decir, como identificador, indicándonos el dia en el que se realizó la medición así que dicho atributo nos es inútil para el aprendizaje de un modelo lineal, y por tanto lo suprimimos:

```{r}
datos_ozone = datos_ozone[,-which(names(datos_ozone) == "doy")]
```


###Conjuntos de training y test usados
A continuación, realizaremos el particionamiento del conjunto de datos. Para el conjunto 'train' de entrenamiento emplearemos el 70% del conjunto total de los datos, de forma que el 30% restante será empleado para test. Hemos decidido utilizar este porcentaje dado que se nos ha explicado que un buen reparto entre train y test oscila entre dos terceras partes para train, o bien hasta un 80%, utilizando el resto para test. Como en el problema anterior empleamos 80-20, en este probaremos con 70-30.\newline
Procedemos al particionamiento de los datos, así como a su almacenamiento en respectivas variables:

```{r}
#Si queremos obtener un conjunto de indices train para luego ejecutar un modelo lineal sobre el train:
train = sample (nrow(datos_ozone), round(nrow(datos_ozone)*0.7))
#definimos ambos conjuntos en dos data.frame diferentes:
ozone_train = datos_ozone[train,]
ozone_test = datos_ozone[-train,]
```

###Preprocesamiento de los datos
Antes de entrar en el preprocesamiento, consideramos interesante realizar una vista preliminar de las gráficas de dispersión para cada atributo de la base de datos siendo reflejado con todos los demás. Así obtenemos una matriz simétrica de gráficas.

```{r}
pairs(datos_ozone, pch = 22)
```

Al representar la matriz de gráficas podemos hacernos una primera idea de la dispersión de los datos. Como podemos observar esta dispersión es menor que en el ejercicio de clasificación, a priori los atributos que consideramos que pueden estar sustancialmente relacionados entre sí son 'temp' y 'ibt', 'vh'  y 'temp', 'vh' y 'ibt'.

En este caso, estamos trabajando sobre un conjunto de datos que posee 8 atributos, por para realizar una reducción de datos debemos de estar seguros que se trata de un atributo redundante para el aprendizaje de nuestro modelo lineal.

Veamos entonces si es aconsejable realizar una reducción de la dimensionalidad de los datos mediante la aplicación de PCA (Computing the Principal Components) sobre el conjunto de datos para intentar comprobar si existen atributos redundantes. Estos atributos redundantes podrían ser recombinados en nuevas características producto de combinaciones lineales de ellos. Prestaremos especial atención a los atributos mencionados anteriormente. \newline

PCA calcula la varianza de cada atributo respecto a los demás, de forma que aquellos atributos que posean menor varianza (cercana a cero) con respecto a los demás serán considerados como redundantes.\newline

Además, para no arriesgar mucho (puesto que PCA trabaja "a ciegas") representaremos sólo aquellos componentes que expliquen hasta el 90% de la variabilidad de los datos (es necesario que los datos estén escalados y centrados para aplicar PCA):


```{r}
ozoneTrans = preProcess(datos_ozone, method = c("BoxCox", "center", "scale", "pca"),thresh = 0.9)
ozoneTrans$rotation
```

Como podemos observar en la tabla, se han reducido los atributos a 5 (combinaciones lineales de los 8 anteriores). Pero si observamos las varianzas de cada atributo en la tabla respecto al resto de atributos, vemos que no existe ningun atributo cuyas varianzas sean cercanas todas a 0. Aún así, para asegurarnos lo comprobamos mediante la siguiente función:

```{r}
nearZeroVar(ozoneTrans$rotation)
```

Para aplicar las transformaciones, emplearemos la función preProcess sobre nuestro conjunto train, tal y como hemos hecho en el problema de clasificación, de forma que realizando un predict sobre el objeto transformación obtenido, obtengamos el conjunto de datos train preprocesado. A continuación, realizaremos las mismas transformaciones sobre el conjunto de test, utilizando el mismo objeto transformación:

```{r}
ozoneTrans = preProcess(ozone_train[,-which(names(datos_ozone) == "ozone")], method = c("BoxCox", "center", "scale"),thresh = 0.9)
ozone_train[,-which(names(ozone_train) == "ozone")] =predict(ozoneTrans,ozone_train[,-which(names(ozone_train) == "ozone")])
ozone_test[,-which(names(ozone_test) == "ozone")] =predict(ozoneTrans,ozone_test[,-which(names(ozone_test) == "ozone")])
```

###Estimación de parámetros
Antes de realizar un modelo, veamos cuáles son las características más representativas (las que ofrecen varianza mayor con respecto al resto de datos), de forma que no empecemos a realizar modelos a ciegas, sino fijándonos en la calidad de sus atributos.\newline

Para ello emplearemos la función regsubsets. Esta función realiza una búsqueda exhaustiva (empleando Branch&Bound) de las mejores agrupaciones de atributos en nuestro conjunto de entrenamiento para predecir en una regresión lineal:

```{r}
regsub_ozone =regsubsets(datos_ozone[,-which(names(datos_ozone) == "ozone")], datos_ozone[,which(names(datos_ozone) == "ozone")])

summary(regsub_ozone)
```

En la gráfica aportada por la función, obtenemos los atributos más representativos en caso de realizar un modelo con 'n' parámetros (filas), de forma que según el número de atributos que deseemos para nuestro modelo nos estíma cuales serían los parámetros más representativos a emplear. Nuestro criterio a seguir a la hora de generar modelos lineales será, no obstante, tratar de predecir utilizando las agrupaciones de atributos que la función considera representativos, es decir, si queremos realizar un modelo con n características, utilizaremos aquellas que estén marcadas con una estrella para la fila n. Para mostrar un ejemplo que explique la gráfica, si queremos utilizar 3 atributos para el modelo, escogeremos 'humidity', 'temp' e 'ibh'.

Ahora que sabemos cuáles son las características más recomendables para realizar modelos, podremos construir una serie de ellos con algunas de estas características y validar con el conjunto de test para comprobar los errores que reflejan.


###Regularización

Procedamos ahora  a realizar un análisis para ver si es interesante aplicar una regularización empleando Weight-decay mediante la función glmnet. Dicha función recibe los siguientes hiperparámetros:

* \textbf{Alpha}: Para aplicar el weight-decay utilizaremos dicho argumento con valor 0.

* \textbf{Lambda}: Parámetro de regularización. (Multiplica la matriz de identidad)

Hace falta tener en cuenta antes la correcta elección del lambda, de forma que escojamos el que mejores resultados nos pueda arrojar. En lugar de seleccionarlo de forma arbitraria, será mejor emplear validación cruzada:

```{r}
variable_respuesta = ozone_train[,which(names(ozone_train) == "ozone")]
tr = ozone_train[,-which(names(ozone_train) == "ozone")]
tr = as.matrix(tr)
crossvalidation =cv.glmnet(tr,variable_respuesta,alpha=0)
print(crossvalidation$lambda.min)
```
Una vez obtenido el lambda que proporciona un menor $E_{out}$, procedemos a generar un modelo de regularización, en primer lugar empleando el valor de lambda generado por validación cruzada, y en segundo lugar empleando un lambda igual a cero, de forma que no apliquemos regularización. El objetivo será comprobar si los parámetros obtenidos son significativamente diferentes como para que merezca la pena realizar regularización en nuestros modelos.

```{r}
modelo_reg = glmnet(tr,variable_respuesta,alpha=0,lambda=crossvalidation$lambda.min)
print(modelo_reg)
```

Aplicando regularización con el lambda obtenido tras la validación cruzada obtenemos una desviación del 0.701. Probemos ahora no aplizando regularización, empleando un hiperparámetro lambda de 0, y comprobemos su desviación:

```{r}
modelo_reg = glmnet(tr,variable_respuesta,alpha=0,lambda=0)
print(modelo_reg)
```

Como podemos comprobar, las desviaciones obtenidas empleando o no regularización mediante weight-decay son similares (0.701 frente a 0.707), por tanto, comcluimos en que emplear regularización no merece la pena.

###Definición de modelos

Para la realización de los modelos planteamos emplear regresión logística mediante la función 'glm'; pero si empleamos regresión logística obtendremos un conjunto de probabilidades que predigan los valores. Para ello, como precondición sería necesario normalizar los valores de la variable respuesta de forma que se encontraran en el intervalo [0,1].

Entonces procederemos a generar modelos mediante regresión lineal, así obtendremos un valor dependiendo de la distancia de los atributos a la recta generada.

Antes definimos una función para el cálculo del error. Para ello realizamos un cálculo de la media de errores normalizados en un intervalo. Se realiza el cociente entre la resta de las variables respuesta reales menos las predichas, y la diferencia entre el valor máximo y mínimo de las variables respuesta:

```{r calculoErrorMedioIntervalo}

calculoErrorMedioIntervalo  = function (modelo, test, variable_respuesta){
  prob_test = predict(modelo, test[,-which(names(test) == variable_respuesta)])

  etest = mean(abs(prob_test - test[,which(names(test) == variable_respuesta)])/(max(ozone_test$ozone)-min(ozone_test$ozone)))

}
```

Comenzamos planteando los modelos con uno sencillo, tratando de predecir la variable respuesta en función únicamente de aquella que recomienda regsubsets, 'temp':

```{r}
m1_ozone = lm(ozone ~ temp, data = ozone_train)
```

En regresión puede ser interesante visualizar la variable respuesta contra la que se está utilizando para predecir, y ver la función que nos pinta el modelo. Representemos por tanto el modelo generado en función del atributo 'temp':

```{r}
plot(ozone_test$temp, ozone_test$ozone)
abline(m1_ozone$coefficients)
```

Como podemos observar, se ajusta un modelo de regresión lineal que parece ciertamente representativo de los datos de test, pero veamos ahora el error obtenido  para asegurar que se trata de un buen modelo:

```{r}
etest_m1ozone = calculoErrorMedioIntervalo(m1_ozone, ozone_test, "ozone")
etest_m1ozone
```

Obtenemos un error de 0.109, para una primera aproximación no está nada mal. No obstante, vamos a seguir haciendo modelos utilizando las agrupaciones de atributos más representativas. Añadimos al siguiente modelo el atributo 'ibh':

```{r}
m2_ozone = lm(ozone ~ temp + ibh, data = ozone_train)

etest_m2ozone = calculoErrorMedioIntervalo(m2_ozone, ozone_test, "ozone")
etest_m2ozone
```

El error desciende hasta 0.102 cuando utilizamos dos características para predecir. Continuemos el proceso con las tres características más representativas, añadiendo 'humidity':

```{r}
m3_ozone = lm(ozone ~ temp + ibh + humidity, data = ozone_train)

etest_m3ozone = calculoErrorMedioIntervalo(m3_ozone, ozone_test, "ozone")
etest_m3ozone
```

Mejoramos el error, llegando hasta 0.096. Añadimos un nuevo atributo, llegando a una combinación lineal de 4, con 'vis' y evaluamos de nuevo el modelo que obtengamos:

```{r}
m4_ozone = lm(ozone ~ temp + ibh + humidity + vis , data = ozone_train)

etest_m4ozone = calculoErrorMedioIntervalo(m4_ozone, ozone_test, "ozone")
etest_m4ozone
```

En este punto la mejora es muy pequeña, el error apenas varía. Por este motivo vamos a sustituir la última característica añadida por la que regsubsets nos recomienda añadir en el caso de calcular un modelo con 5 características, 'ibt':

```{r}
m5_ozone = lm(ozone ~ temp + ibh + humidity + ibt, data = ozone_train)

etest_m5ozone = calculoErrorMedioIntervalo(m5_ozone, ozone_test, "ozone")
etest_m5ozone
```

Añadiendo este atributo sí hemos conseguido una mejora más significativa, 0.095. Por hacernos una idea, generemos también el modelo que contiene las 5 características juntas:

```{r}
m6_ozone = lm(ozone ~ temp + ibh + humidity + vis + ibt, data = ozone_train)

etest_m6ozone = calculoErrorMedioIntervalo(m6_ozone, ozone_test, "ozone")
etest_m6ozone
```

En este punto obtenemos un error ligeramente mayor que en el modelo anterior, por lo que tomamos la decisión de que en lugar de añadir más atributos a nuestro modelo de regresión de forma lineal, vamos a realizar transformaciones no lineales sobre el conjunto de atributos del mejor modelo obtenido hasta el momento:

```{r}
m7_ozone = lm(ozone ~ temp * ibh * humidity * ibt , data = ozone_train)

etest_m7ozone = calculoErrorMedioIntervalo(m7_ozone, ozone_test, "ozone")
etest_m7ozone
```

Con este modelo no lineal, utilizando el producto de las características, el error desciende considerablemente, dando lugar a un 0.086.

De nuevo no es productivo aplicar raíces cuadradas ni logaritmos por la cantidad de valores negativos que surjan de la normalización de los datos. Dado que esas cuatro características son aquellas que nos han aportado el mejor modelo lineal, concluimos que utilizarlas como transformación no lineal es el mejor modelo que podemos obtener.

###Estimacion del error $E_{out}$
Una vez que hemos comprobado qué modelo nos aporta un mejor resultado, vamos a proceder a realizar una estimación del $E_{out}$ de forma que obtengamos un valor más representativo que un error puntual en un par de conjuntos train-test.

Para ello vamos a realizar un experimento repitiendo el proceso completo, desde la generación de particiones, tanto train como test, con la misma proporción realizada anteriormente (0.7 para train y 0.3 para test), hasta la definición de los modelos y cálculo del $E_{test}$. Repetiremos el proceso 100 veces y obtendremos la media de los $E_{test}$, considerándolo una buena estimación del $E_{out}$ para el modelo.

Definamos una función que realice tanto la generación y el particionado, así como las transformaciones sobre los conjuntos de datos y que devuelva el error generado por el mejor modelo obtenido:

```{r generaErrorParticionOzone}
generarErrorParticionOzone = function(datos){
  #Si queremos obtener un conjunto de indices train para luego
  #ejecutar un modelo lineal sobre el train:
  train = sample (nrow(datos), round(nrow(datos)*0.7))
  #definimos ambos conjuntos en dos data.frame diferentes:
  ozone_train = datos_ozone[train,]
  ozone_test = datos_ozone[-train,]

  #TRANSFORMACIONES:
  ozoneTrans = preProcess(ozone_train[,-which(names(datos_ozone) == "ozone")], method = c("BoxCox", "center", "scale"),thresh = 0.8)
ozone_train[,-which(names(ozone_train) == "ozone")] =predict(ozoneTrans,ozone_train[,-which(names(ozone_train) == "ozone")])
ozone_test[,-which(names(ozone_test) == "ozone")] =predict(ozoneTrans,ozone_test[,-which(names(ozone_test) == "ozone")])

#EVALUACION DEL MODELO
modelo_ozone = lm(ozone ~ temp * ibh * humidity * ibt, data = ozone_train)

etest = calculoErrorMedioIntervalo(modelo_ozone, ozone_test, "ozone")
etest
}
```


Una vez que hemos definido la funcion, realizamos una evaluación del error 100 veces, de forma que calculemos como resultado final la media de los errores generados para cada una de las 100 particiones:

```{r}
mean(replicate(100, generarErrorParticionOzone(datos_ozone)))
```

Como podemos ver, obtenemos un $E_{out}$ medio del 0.084, aún mejor que en el caso particular al que sometimos el modelo al principio. Este error representa de forma mucho más fiable el error real obtenido por nuestro modelo, y le da más validez y consistencia.

###Conclusión y modelo final seleccionado

Una vez que hemos generado distintos modelos de regresión lineal, sin haber aplicado regularización al comprobar que la desviación no varía de forma significativa entre hacerla y no hacerla, y habiendo utilizado distintas agrupaciones de atributos tratando de optimizar con transformaciones no lineales, hemos concluido que el mejor modelo que hemos podido encontrar ha sido aquel que utiliza la agrupación del producto de 4 atributos de los recomendados de regsubsets. No obstante, variamos ligeramente la agrupación sustituyendo un atributo, ya que de forma experimental comprobamos que daba mejor resultado.  

Con este modelo hemos reducido la tasa de error hasta un 8.6% con los conjuntos generados inicialmente. Según hemos comprobado de forma experimental, al encontrar un error por debajo de 10% podemos asumir que la base de datos es lineal, y con un modelo lineal podremos ajustar bastante bien los datos. Decidimos empezar por combinaciones lineales de los atributos para encontrar qué características son más representativas a la hora de reducir el error. Hemos construido diferentes modelos combinando los atributos que mayor varianza presentan (más representativos) y hemos ido reduciendo el error hasta que se ha empezado a producir un ligero sobreajuste. A partir de aquí, añadir más atributos sólo nos continúa sobreajustando la función, provocando que se produzcan muchas curvas en la función que dificulten generalizar los datos del conjunto de test.

Llegados a este punto, como no nos conviene añadir más atributos, consideramos realizar algunas transformaciones no lineales sobre los atributos que ya tenemos, y encontramos el mejor error realizando una transformación con el producto sobre los mismos. Dado que es un problema donde hemos comprobado que un modelo lineal se va ajustando aceptablemente a los datos, decidimos probar con una transformación no lineal que se pudiese acercar mejor a los valores de la variable respuesta.

A pesar de todo, el error que da en estos conjuntos train-test no nos aporta más que una valoración puntual del modelo, por lo que hemos considerado oportuno realizar 100 versiones del modelo realizando distintas particiones de los datos, a fin de poder obtener un error medio más representativo y que resulte en una buena estimación del $E_{out}$. El error medio obtenido es incluso mejor, y además resulta mucho más válido al tratarse de un error contrastado en un número considerable de casos, y no en un caso puntual como era el primero que obtuvimos.

Como conclusión final, un modelo que utilice suficiente número de atributos para predecir (sin llegar al límite de sobreajuste) y que contenga algún tipo de transformación no lineal es comprensible que refleje buenos resultados en un problema real de regresión. Dentro de los distintos modelos que cumplan esas características, de forma experimental hemos seleccionado el anteriormente mencionado porque nos ofrecía un error muy aceptable para lo que esperábamos encontrar.
